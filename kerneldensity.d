/**This module contains a small but growing library for performing kernel
 * density estimation.  This module is definitely a work in progress and will
 * be fleshed out in the future.
 *
 * Author:  David Simcha
 */
/*
 * License:
 * Boost Software License - Version 1.0 - August 17th, 2003
 *
 * Permission is hereby granted, free of charge, to any person or organization
 * obtaining a copy of the software and accompanying documentation covered by
 * this license (the "Software") to use, reproduce, display, distribute,
 * execute, and transmit the Software, and to prepare derivative works of the
 * Software, and to permit third-parties to whom the Software is furnished to
 * do so, all subject to the following:
 *
 * The copyright notices in the Software and this entire statement, including
 * the above license grant, this restriction and the following disclaimer,
 * must be included in all copies of the Software, in whole or in part, and
 * all derivative works of the Software, unless such copies or derivative
 * works are solely in the form of machine-executable object code generated by
 * a source language processor.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
 * SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
 * FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */
module dstats.kerneldensity;

import std.conv, std.math, std.algorithm, std.contracts, std.traits, std.range;

import  dstats.alloc, dstats.summary;

version(unittest) {

    import dstats.distrib, std.stdio;

    void main() {}
}

/**Estimates densities in the 1-dimensional case.  The 1-D case is special
 * enough to be treated as a special case, though eventually a general N-D
 * case will be added.
 *
 * Under the hood, this works by binning the data into a large number of bins
 * (currently 1,000), convolving it with the kernel function to smooth it, and
 * then using linear interpolation to evaluate the density estimates.  This
 * means that constructing this object is relatively expensive, but evaluating
 * a density estimate can be done in O(1) time complexity afterwords.
 */
class KernelDensity1D {
private:
    immutable double[] bins;
    immutable double minElem;
    immutable double maxElem;

    this(immutable double[] bins, double minElem, double maxElem) {
        this.bins = bins;
        this.minElem = minElem;
        this.maxElem = maxElem;
    }

    private static double findEdgeBuffer(C)(C kernel) {
        // Search for the approx. point where the kernel's density is 0.001 *
        // what it is at zero.
        immutable zeroVal = kernel(0);
        double ret = 1;

        while(kernel(ret) / zeroVal > 1e-3) {
            ret *= 2;
        }

        while(kernel(ret) / zeroVal < 1e-4) {
            ret *= 0.5;
        }

        return ret;
    }

public:
    /**Construct a kernel density estimation object from a callable object.
     * R must be a range of numeric types.  C must be a kernel function,
     * delegate, or class or struct with overloaded opCall.  The kernel
     * function is assumed to be symmetric about zero, to take its maximum
     * value at zero and to be unimodal.
     *
     * edgeBuffer determines how much space below and above the smallest and
     * largest observed value will be allocated when doing the binning.
     * Values less than reduce!min(range) - edgeBuffer or greater than
     * reduce!max(range) + edgeBuffer will be assigned a probability of zero.
     * If this value is left at its default, it will be set to a value at which
     * the kernel is between 1e-3 and 1e-4 times its value at zero.
     *
     * The bandwidth of the kernel is indirectly selected by parametrizing the
     * kernel function.
     *
     * Examples:
     * ---
     * auto randNums = randArray!rNorm(1_000, 0, 1);
     * auto kernel = parametrize!normalPDF(0, 0.01);
     * auto density = KernelDensity1D(randNums, kernel);
     * writeln(normalPDF(1, 0, 1), "  ", density(1)).  // Should be about the same.
     * ---
     */
    static KernelDensity1D fromCallable(R, C)
    (R range, C kernel, double edgeBuffer = double.nan)
    if(isForwardRange!R && is(typeof(kernel(2.0)) : double)) {
        enum nBin = 1000;
        mixin(newFrame);

        uint N = 0;
        double minElem = double.infinity;
        double maxElem = -double.infinity;
        foreach(elem; range) {
            minElem = min(minElem, elem);
            maxElem = max(maxElem, elem);
            N++;
        }

        if(isNaN(edgeBuffer)) {
            edgeBuffer = findEdgeBuffer(kernel) / N;
        }
        minElem -= edgeBuffer;
        maxElem += edgeBuffer;

        auto binsRaw = newStack!uint(nBin);
        foreach(elemRaw; range) {
            double elem = elemRaw - minElem;
            elem /= (maxElem - minElem);
            elem *= nBin;
            auto bin = to!uint(elem);
            if(bin == nBin) {
                bin--;
            }

            binsRaw[bin]++;
        }

        // Convolve the binned data with our kernel.  Since N is fairly small
        // we'll use a simple, accurate, memory efficient and readable
        // algorithm instead of messing with FFTs, at least until the FFT
        // algorithm works better than it does now.
        auto binsCooked = new double[nBin];

        immutable stepSize = (maxElem - minElem) / nBin;
        foreach(i, ref elem; binsCooked) {
            elem = kernel(0) * binsRaw[i];

            foreach(offset; 1..max(i + 1, nBin - i)) {
                immutable kernelVal = kernel(stepSize * offset);

                if(i >= offset) {
                    elem += kernelVal * binsRaw[i - offset];
                }

                if(i + offset < nBin) {
                    elem += kernelVal * binsRaw[i + offset];
                }
            }
        }

        binsCooked[] /= sum(binsCooked);
        binsCooked[] *= nBin / (maxElem - minElem);  // Make it a density.
        return new typeof(this)(assumeUnique(binsCooked), minElem, maxElem);
    }

    /**Construct a kernel density estimator from an alias.*/
    static KernelDensity1D fromAlias(alias kernel, R)
    (R range, double edgeBuffer = double.nan)
    if(isForwardRange!R && is(typeof(kernel(2.0)) : double)) {
        static double kernelFun(double x) {
            return kernel(x);
        }

        return fromCallable(range, &kernelFun, edgeBuffer);
    }

    /**Compute the probability density at a given point.*/
    double opCall(double x) const {
        if(x < minElem || x > maxElem) {
            return 0;
        }

        x -= minElem;
        x /= (maxElem - minElem);
        x *= bins.length;

        immutable fract = floor(x) - x;
        immutable upper = to!size_t(ceil(x));
        immutable lower = to!size_t(floor(x));

        if(upper == bins.length) {
            return bins[$ - 1];
        }

        immutable ret = fract * bins[upper] + (1 - fract) * bins[lower];
        return max(0, ret);  // Compensate for roundoff
    }
}

unittest {
    auto kde = KernelDensity1D.fromCallable([0], parametrize!normalPDF(0, 1));
    assert(approxEqual(kde(1), normalPDF(1)));

    // This is purely to see if fromAlias works.
    auto cosKde = KernelDensity1D.fromAlias!cos([0], 1);
}
