
<html><head>
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta content="text/javascript" http-equiv="content-script-type">
<title>dstats.infotheory</title>
<link rel="stylesheet" type="text/css" href="candydoc/style.css">
<!--[if lt IE 7]><link rel="stylesheet" type="text/css" href="candydoc/ie56hack.css"><![endif]-->
<script language="JavaScript" src="candydoc/util.js" type="text/javascript"></script>
<script language="JavaScript" src="candydoc/tree.js" type="text/javascript"></script>
<script language="JavaScript" src="candydoc/explorer.js" type="text/javascript"></script>
</head><body>
<div id="tabarea"></div><div id="explorerclient"></div>
<div id="content"><script>explorer.initialize("dstats.infotheory");</script>
	<table class="content">
		<tr><td id="docbody"><h1>dstats.infotheory</h1><!-- Generated by Ddoc from dstats\infotheory.d -->
Basic information theory.  Joint entropy, mutual information, conditional
 mutual information.  This module uses the base 2 definition of these
 quantities, i.e, entropy, mutual info, etc. are output in bits.
<br><br>
<b>Author:</b><br>
David Simcha<br><br>


<script>explorer.outline.incSymbolLevel();</script>
<dl>
<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">entropyCounts</span>
<script>explorer.outline.addDecl('entropyCounts');</script>

(T)(T <span class="funcparam">data</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>This function calculates the Shannon entropy of a forward range that is
 treated as frequency counts of a set of discrete observations.
<br><br>
<b>Examples:</b><br>
<pre class="d_code"> <font color=blue>double</font> uniform3 = <u>entropyCounts</u>([4, 4, 4]);
 <font color=blue>assert</font>(approxEqual(uniform3, log2(3)));
 <font color=blue>double</font> uniform4 = <u>entropyCounts</u>([5, 5, 5, 5]);
 <font color=blue>assert</font>(approxEqual(uniform4, 2));
</pre>
<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">Joint!(FlattenType!(T)) 
<span class="currsymbol">joint</span>
<script>explorer.outline.addDecl('joint');</script>

(T...)(T <span class="funcparam">args</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Bind a set of ranges together to represent a 
<span class="currsymbol">joint</span>
<script>explorer.outline.addDecl('joint');</script>

 probability distribution.
<br><br>
<b>Examples:</b><br>
<pre class="d_code"> <font color=blue>auto</font> foo = [1,2,3,1,1];
 <font color=blue>auto</font> bar = [2,4,6,2,2];
 <font color=blue>auto</font> e = entropy(<u>joint</u>(foo, bar));  <font color=green>// Calculate joint entropy of foo, bar.
</font></pre>
<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">struct 
<span class="currsymbol">Joint</span>
<script>explorer.outline.addDecl('Joint');</script>

(T...);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Iterate over a set of ranges by value in lockstep and return an ObsEnt,
 which is used internally by entropy functions on each iteration.<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">entropy</span>
<script>explorer.outline.addDecl('entropy');</script>

(T)(T <span class="funcparam">data</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Calculates the joint 
<span class="currsymbol">entropy</span>
<script>explorer.outline.addDecl('entropy');</script>

 of a set of observations.  Each input range
 represents a vector of observations. If only one range is given, this reduces
 to the plain old 
<span class="currsymbol">entropy</span>
<script>explorer.outline.addDecl('entropy');</script>

.  Input range must have a length.
<br><br>
<b>Note:</b><br>
This function specializes if ElementType!(T) is a byte, ubyte, or
 char, resulting in a much faster 
<span class="currsymbol">entropy</span>
<script>explorer.outline.addDecl('entropy');</script>

 calculation.  When possible, try
 to provide data in the form of a byte, ubyte, or char.

<br><br>
<b>Examples:</b><br>
<pre class="d_code"> <font color=blue>int</font>[] foo = [1, 1, 1, 2, 2, 2, 3, 3, 3];
 <font color=blue>double</font> entropyFoo = <u>entropy</u>(foo);  <font color=green>// Plain old entropy of foo.
</font> <font color=blue>assert</font>(approxEqual(entropyFoo, log2(3)));
 <font color=blue>int</font>[] bar = [1, 2, 3, 1, 2, 3, 1, 2, 3];
 <font color=blue>double</font> HFooBar = <u>entropy</u>(joint(foo, bar));  <font color=green>// Joint entropy of foo and bar.
</font> <font color=blue>assert</font>(approxEqual(HFooBar, log2(9)));
</pre>
<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">condEntropy</span>
<script>explorer.outline.addDecl('condEntropy');</script>

(T, U)(T <span class="funcparam">data</span>, U <span class="funcparam">cond</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Calculate the conditional entropy H(data | cond).<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">mutualInfo</span>
<script>explorer.outline.addDecl('mutualInfo');</script>

(T, U)(T <span class="funcparam">x</span>, U <span class="funcparam">y</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Calculates the mutual information of two vectors of discrete observations.<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">mutualInfoTable</span>
<script>explorer.outline.addDecl('mutualInfoTable');</script>

(T...)(T <span class="funcparam">table</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Calculates the mutual information of a contingency table representing a joint
discrete probability distribution.  Takes a set of finite forward ranges,
one for each column in the contingency table.  These can be expressed either as
a tuple of ranges or a range of ranges.<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">condMutualInfo</span>
<script>explorer.outline.addDecl('condMutualInfo');</script>

(T, U, V)(T <span class="funcparam">x</span>, U <span class="funcparam">y</span>, V <span class="funcparam">z</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Calculates the conditional mutual information I(x, y | z) from a set of
observations.<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">entropySorted</span>
<script>explorer.outline.addDecl('entropySorted');</script>

(alias compFun = "a == b", T)(T <span class="funcparam">data</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Calculates the entropy of any old input range of observations more quickly
 than entropy(), provided that all equal values are adjacent.  If the input
 is sorted by more than one key, i.e. structs, the result will be the joint
 entropy of all of the keys.  The compFun alias will be used to compare
 adjacent elements and determine how many instances of each value exist.<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">struct 
<span class="currsymbol">DenseInfoTheory</span>
<script>explorer.outline.addDecl('DenseInfoTheory');</script>

;
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Much faster implementations of information theory functions for the special
but common case where all observations are integers on the range [0, nBin).
This is the case, for example, when the observations have been previously
binned using, for example, dstats.base.frqBin().
<br><br>
Note that, due to the optimizations used, joint() cannot be used with
the member functions of this struct, except entropy().
<br><br>

For those looking for hard numbers, this seems to be on the order of 10x
faster than the generic implementations according to my quick and dirty
benchmarks.<br><br>


<script>explorer.outline.incSymbolLevel();</script>
<dl>
<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">this(uint <span class="funcparam">nBin</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Constructs a DenseInfoTheory object for <span class="funcparam">nBin</span> bins.  The values taken by
    each observation must then be on the interval [0, <span class="funcparam">nBin</span>).<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">entropy</span>
<script>explorer.outline.addDecl('entropy');</script>

(R)(R <span class="funcparam">range</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Computes the 
<span class="currsymbol">entropy</span>
<script>explorer.outline.addDecl('entropy');</script>

 of a set of observations.  Note that, for this
    function, the joint() function can be used to compute joint entropies
    as long as each individual range contains only integers on [0, nBin).<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">mutualInfo</span>
<script>explorer.outline.addDecl('mutualInfo');</script>

(R1, R2)(R1 <span class="funcparam">x</span>, R2 <span class="funcparam">y</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>I(x; y)<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">mutualInfoPval</span>
<script>explorer.outline.addDecl('mutualInfoPval');</script>

(double <span class="funcparam">mutualInfo</span>, double <span class="funcparam">n</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>Calculates the P-value for I(X; Y) assuming x and y both have supports
    of [0, nBin).  The P-value is calculated using a Chi-Square approximation.
    It is asymptotically correct, but is approximate for finite sample size.
<br><br>
<b>Parameters:</b><br>
<br><br>
<b>mutualInfo:</b><br>
I(x; y), in bits
<br><br>
<b>n:</b><br>
The number of samples used to calculate I(x; y)<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">condEntropy</span>
<script>explorer.outline.addDecl('condEntropy');</script>

(R1, R2)(R1 <span class="funcparam">x</span>, R2 <span class="funcparam">y</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>H(X | Y)<br><br>

</dd>

<script>explorer.outline.writeEnabled = true;</script>
<dt><span class="decl">double 
<span class="currsymbol">condMutualInfo</span>
<script>explorer.outline.addDecl('condMutualInfo');</script>

(R1, R2, R3)(R1 <span class="funcparam">x</span>, R2 <span class="funcparam">y</span>, R3 <span class="funcparam">z</span>);
</span></dt>
<script>explorer.outline.writeEnabled = false;</script>


<dd>I(X; Y | Z)<br><br>

</dd>
</dl>
<script>explorer.outline.decSymbolLevel();</script>


</dd>
</dl>
<script>explorer.outline.decSymbolLevel();</script>


</td></tr>
		<tr><td id="docfooter">
			Page was generated with
			<img src="candydoc/img/candydoc.gif" style="vertical-align:middle; position:relative; top:-1px">
			on Thu Aug 18 21:40:07 2011

		</td></tr>
	</table>
</div>
<script>
    explorer.packageExplorer.addModule("dstats.all");
	explorer.packageExplorer.addModule("dstats.alloc");
	explorer.packageExplorer.addModule("dstats.base");
	explorer.packageExplorer.addModule("dstats.cor");
	explorer.packageExplorer.addModule("dstats.distrib");
	explorer.packageExplorer.addModule("dstats.infotheory");
	explorer.packageExplorer.addModule("dstats.random");
	explorer.packageExplorer.addModule("dstats.pca");
	explorer.packageExplorer.addModule("dstats.kerneldensity");
	explorer.packageExplorer.addModule("dstats.regress");	
	explorer.packageExplorer.addModule("dstats.sort");
	explorer.packageExplorer.addModule("dstats.summary");
	explorer.packageExplorer.addModule("dstats.tests");
</script>
</body></html>


